# importing 
from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv("nhanes_cleaned.csv (1).csv")
df.head()
df.isna().sum()


# Load dataset
df = pd.read_csv("nhanes_cleaned.csv (1).csv")
df.head()
df_encoded = df.copy()
cat_cols = df_encoded.select_dtypes(include=['object']).columns
df_encoded = pd.get_dummies(df_encoded, columns=cat_cols, drop_first=True)
num_cols = df_encoded.select_dtypes(include=['float64','int64']).columns
df_encoded[num_cols] = df_encoded[num_cols].fillna(df_encoded[num_cols].mean())

df_encoded.head()

# Choose the prediction target
target = "Had_asthma_Yes"
X = df_encoded.drop(columns=["Patient_ID", target])
y = df_encoded[target]
# Convert y to integers
y = y.astype(int)
X.shape, y.shape
target = "Still_asthma_Yes"
X = df_encoded.drop(columns=["Patient_ID", target])
y = df_encoded[target]
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

#training
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
from sklearn.linear_model import LogisticRegression
log_reg = LogisticRegression(max_iter=5000)
log_reg.fit(X_train_scaled, y_train)

#logistic regression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

#coefficient matrix
log_reg.coef_
coef_df = pd.DataFrame({
    "feature": X.columns,
    "coefficient": log_reg.coef_[0]
}).sort_values(by="coefficient", ascending=False)
coef_df

#random forest
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
print("RF Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

#XGBoost
df_encoded.columns = df_encoded.columns.str.replace(r'[<>]', '', regex=True)
df_encoded.columns = df_encoded.columns.str.replace(r'[^A-Za-z0-9_]+', '_', regex=True)
X = df_encoded.drop(columns=[target])
y = y 

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report
xgb = XGBClassifier(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=5,
    eval_metric="logloss"
)
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)
print("XGB Accuracy:", accuracy_score(y_test, y_pred_xgb))
print(classification_report(y_test, y_pred_xgb))

# ROC AUC curve and ROC score
from sklearn.metrics import roc_auc_score, roc_curve
import matplotlib.pyplot as plt

roc_auc = roc_auc_score(y_test, y_proba_rf)
print("ROC-AUC:", roc_auc)

fpr, tpr, thresholds = roc_curve(y_test, y_proba_rf)

plt.figure(figsize=(7,5))
plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc:.3f})")
plt.plot([0,1], [0,1], linestyle="--", color="grey")  # diagonal line
plt.xlabel("False Positive Rate")
plt.ylabel("Sensitivity")
plt.title("ROC Curve - Random Forest")
plt.legend()
plt.show()

#precision sensitivty scofre and curve
from sklearn.metrics import precision_recall_curve, average_precision_score
precision, recall, thresholds = precision_recall_curve(y_test, y_proba_rf)
pr_auc = average_precision_score(y_test, y_proba_rf)
print("Precision-Recall AUC:", pr_auc)
plt.figure(figsize=(7,5))
plt.plot(recall, precision, label=f"PR Curve (AUC = {pr_auc:.3f})")
plt.xlabel("Sensitivity")
plt.ylabel("Precision")
plt.title("Precision, Sensitivity- Random Forest")
plt.legend()
plt.show()
